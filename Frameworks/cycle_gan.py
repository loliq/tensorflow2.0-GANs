#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2019/12/17 15:52
# @Author  : LLL
# @Site    : 
# @File    : cycle_gan.py
# @Software: PyCharm
"""
ä»£ç å‚è€ƒ tensorflow2.0 çš„å®˜æ–¹æ•™ç¨‹: https://www.tensorflow.org/tutorials/generative/cyclegan
æ¨¡åž‹ç»“æž„ä¸Žpixeel2pixelç›¸ä¼¼ï¼Œ ä½†æ˜¯æœ‰ä¸‹é¢ä¸€äº›ä¸åŒç‚¹:
1. cycle_gan ä½¿ç”¨çš„æ˜¯`instance normalization`, è€Œä¸æ˜¯`batch normalization`
2. cycle_gan ä½¿ç”¨çš„æ˜¯ä¸€ç§åŸºäºŽ`resnet`çš„æ”¹è¿›ç”Ÿæˆå™¨ï¼Œè¿™è¾¹ä¸ºäº†ç®€å•ä½¿ç”¨çš„æ˜¯æ”¹è¿›çš„`unet`ç”Ÿæˆå™¨ã€‚
ç”Ÿæˆå™¨ G å­¦ä¹ å°†å›¾ç‰‡ X è½¬æ¢ä¸º Yã€‚  (ðº:ð‘‹âˆ’>ð‘Œ) (ðº:ð‘‹âˆ’>ð‘Œ) ç”Ÿæˆç½‘ç»œç»“æž„ç±»ä¼¼äºŽautoencoder
ç”Ÿæˆå™¨ F å­¦ä¹ å°†å›¾ç‰‡ Y è½¬æ¢ä¸º Xã€‚  (ð¹:ð‘Œâˆ’>ð‘‹)  (ð¹:ð‘Œâˆ’>ð‘‹) # ç”Ÿæˆç½‘ç»œç±»ä¼¼äºŽ autoencoder
åˆ¤åˆ«å™¨ D_X å­¦ä¹ åŒºåˆ†å›¾ç‰‡ X ä¸Žç”Ÿæˆçš„å›¾ç‰‡ X (F(Y))ã€‚
åˆ¤åˆ«å™¨ D_Y å­¦ä¹ åŒºåˆ†å›¾ç‰‡ Y ä¸Žç”Ÿæˆçš„å›¾ç‰‡ Y (G(X))ã€‚
# TODO è¿™è¾¹ç”¨äº†è°·æ­Œå®˜æ–¹å®šä¹‰çš„ç½‘ç»œï¼Œæ‰€ä»¥ç”Ÿæˆå›¾ç‰‡å¤§å°ä¸º[256, 256]ï¼Œç›®å‰ä¼¼ä¹Žæ”¹ä¸äº†ä¼šæŠ¥é”™
"""

import tensorflow as tf
import time
import os
from utils.utils import check_make_folders, read_json
from glob import glob
import math
from utils.utils_cyclegan import make_dataset, generate_images, test_dataset
from Models import pix2pix
from tqdm import tqdm
import argparse

# æŠ¥é”™äº†ï¼ŒæŠ¥äº† å’Œä¼ å…¥python å‚æ•°ä¸€æ ·çš„é”™ï¼Œä¼°è®¡æ˜¯æ˜¾å­˜ä¸å¤Ÿï¼ŒåŽé¢æ¢æœåŠ¡å™¨å†è¯•è¯•

parser = argparse.ArgumentParser()
parser.add_argument('--config_path', required=False, default="configs/cycle_gan_dent.json", help='path of config')
args = parser.parse_args()


class Cycle_gan(tf.keras.Model):
    def __init__(self, **kwargs):
        """

        :param kwargs:
        - LAMBDAï¼š å¾ªçŽ¯ä¸€è‡´æ€§æŸå¤±(X_reconstruct - X) å’Œ ä¸€è‡´æ€§æŸå¤±( G(X) - X) çš„æƒé‡
        - generator_g : ç”Ÿæˆå™¨G: X-Yçš„è½¬æ¢ï¼š tf.keras.Model
        - generator_f : ç”Ÿæˆå™¨ Fï¼šY->Xçš„è½¬æ¢ ï¼š tf.keras.Model
        - discriminator_x : åˆ¤æ–­ æ˜¯å¦ä¸ºXåŸŸå†…çš„å›¾åƒçš„model ï¼štf.keras.Model
        - discriminator_y: åˆ¤æ–­ æ˜¯å¦ä¸ºYåŸŸå†…çš„å›¾åƒçš„ ï¼štf.keras.Model
        - generator_g_optimizerï¼š ç”Ÿæˆå™¨Gçš„ä¼˜åŒ–å™¨ï¼š tf.keras.optimizers
        - generator_f_optimizerï¼šç”Ÿæˆå™¨Fçš„ä¼˜åŒ–å™¨ ï¼š tf.keras.optimizers
        - discriminator_x_optimizerï¼š åˆ¤åˆ«æ˜¯å¦ä¸ºXåŸŸçš„ ä¼˜åŒ–å™¨ï¼štf.keras.optimizers
        - discriminator_y_optimizerï¼šåˆ¤åˆ«æ˜¯å¦ä¸ºXåŸŸçš„ ä¼˜åŒ–å™¨ï¼štf.keras.optimizers
        """
        super(Cycle_gan, self).__init__()
        self.__dict__.update(kwargs)
        self.loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)
        self.ckpt = tf.train.Checkpoint(generator_g=self.generator_g,
                                   generator_f=self.generator_f,
                                   discriminator_x=self.discriminator_x,
                                   discriminator_y=self.discriminator_y,
                                   generator_g_optimizer=self.generator_g_optimizer,
                                   generator_f_optimizer=self.generator_f_optimizer,
                                   discriminator_x_optimizer=self.discriminator_x_optimizer,
                                   discriminator_y_optimizer=self.discriminator_y_optimizer)


    def discriminator_loss(self, real, generated):
        """
        èŽ·å¾—dçš„æŸå¤±
        :param real:
        :param generated:
        :return:
        """
        real_loss = self.loss_obj(tf.ones_like(real), real)

        generated_loss = self.loss_obj(tf.zeros_like(generated), generated)

        total_disc_loss = real_loss + generated_loss

        return total_disc_loss * 0.5

    def generator_loss(self, generated):
        """
        èŽ·å¾—D çš„æŸå¤±
        :param generated:
        :return:
        """
        return self.loss_obj(tf.ones_like(generated), generated)

    def calc_cycle_loss(self, real_image, cycled_image):
        """
        å¾ªçŽ¯ä¸€è‡´æ€§çš„æŸå¤±ï¼Œæ ¹æ®cycle gançš„åŽŸç†
        å¾ªçŽ¯ä¸€è‡´æ„å‘³ç€é‡å»ºçš„åº”æŽ¥è¿‘åŽŸå§‹è¾“å‡º
        X -> G(X ) ->F(G(X )) -> X' æ¢å¤çš„å›¾ X' è¦å’Œ X æœ‰ä¸€å®šçš„ç›¸ä¼¼æ€§ï¼Œ
        åŒç† Y åŸŸçš„å›¾ç‰‡
        Y -> G(Y) ->F(G(Y)) -> Y'
        :param real_image:
        :param cycled_image:
        :return:
        """
        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))

        return self.LAMBDA * loss1

    def identity_loss(self, real_image, same_image):
        """
        å¦‚ä¸Šæ‰€ç¤ºï¼Œç”Ÿæˆå™¨  ðº  è´Ÿè´£å°†å›¾ç‰‡  ð‘‹  è½¬æ¢ä¸º  ð‘Œ ã€‚
        ä¸€è‡´æ€§æŸå¤±è¡¨æ˜Žï¼Œå¦‚æžœæ‚¨å°†å›¾ç‰‡  ð‘Œ  é¦ˆé€ç»™ç”Ÿæˆå™¨  ðº ï¼Œå®ƒåº”å½“ç”ŸæˆçœŸå®žå›¾ç‰‡  ð‘Œ  æˆ–æŽ¥è¿‘äºŽ  ð‘Œ  çš„å›¾ç‰‡ã€‚
        :param same_image:
        :return:
        """
        loss = tf.reduce_mean(tf.abs(real_image - same_image))
        return self.LAMBDA * 0.5 * loss

    def compute_gradients(self, real_x, real_y):
        """
         è®¡ç®—æ¢¯åº¦
        :param real_x:
        :param real_y:
        :return:
        """
        # persistent è®¾ç½®ä¸º Tureï¼Œå› ä¸º GradientTape è¢«å¤šæ¬¡åº”ç”¨äºŽè®¡ç®—æ¢¯åº¦ã€‚
        with tf.GradientTape(persistent=True) as tape:

            # real_xé€šè¿‡ ç”Ÿæˆ fake_y, fake_y ç»è¿‡F ç”Ÿæˆ é‡å»ºçš„cycled(real_x)
            fake_y = self.generator_g(real_x, training=True)
            cycled_x = self.generator_f(fake_y, training=True)

            # real_y é€šè¿‡ Fç”Ÿæˆ fake_x, fake_xé€šè¿‡Gç”Ÿæˆé‡å»ºçš„cycled(real_y)
            fake_x = self.generator_f(real_y, training=True)
            cycled_y = self.generator_g(fake_x, training=True)

            # same_x å’Œ same_y ç”¨äºŽä¸€è‡´æ€§æŸå¤±ã€‚
            same_x = self.generator_f(real_x, training=True)
            same_y = self.generator_g(real_y, training=True)

            disc_real_x = self.discriminator_x(real_x, training=True)
            disc_real_y = self.discriminator_y(real_y, training=True)

            disc_fake_x = self.discriminator_x(fake_x, training=True)
            disc_fake_y = self.discriminator_y(fake_y, training=True)

            gen_g_loss = self.generator_loss(disc_fake_y)
            gen_f_loss = self.generator_loss(disc_fake_x)

            total_cycle_loss = self.calc_cycle_loss(real_x, cycled_x) \
                               + self.calc_cycle_loss(real_y, cycled_y)

            # æ€»ç”Ÿæˆå™¨æŸå¤± = å¯¹æŠ—æ€§æŸå¤± + å¾ªçŽ¯æŸå¤±ã€‚
            total_gen_g_loss = gen_g_loss + total_cycle_loss + self.identity_loss(real_y, same_y)
            total_gen_f_loss = gen_f_loss + total_cycle_loss + self.identity_loss(real_x, same_x)

            # æ€»çš„è¾¨åˆ«å™¨æŸå¤±
            disc_x_loss = self.discriminator_loss(disc_real_x, disc_fake_x)
            disc_y_loss = self.discriminator_loss(disc_real_y, disc_fake_y)

        generator_g_gradients = tape.gradient(total_gen_g_loss,
                                              self.generator_g.trainable_variables)
        generator_f_gradients = tape.gradient(total_gen_f_loss,
                                              self.generator_f.trainable_variables)

        discriminator_x_gradients = tape.gradient(disc_x_loss,
                                                  self.discriminator_x.trainable_variables)
        discriminator_y_gradients = tape.gradient(disc_y_loss,
                                                  self.discriminator_y.trainable_variables)

        return generator_g_gradients, generator_f_gradients, discriminator_x_gradients, discriminator_y_gradients

    def apply_gradients(self, gen_g_gradients,gen_f_gradients, disc_x_gradients, disc_y_gradients):
        """

        :param gen_g_gradients:
        :param gen_f_gradients:
        :param disc_x_gradients:
        :param disc_y_gradients:
        :return:
        """
        self.generator_g_optimizer.apply_gradients(zip(gen_g_gradients,
                                                  self.generator_g.trainable_variables))

        self.generator_f_optimizer.apply_gradients(zip(gen_f_gradients,
                                                  self.generator_f.trainable_variables))

        self.discriminator_x_optimizer.apply_gradients(zip(disc_x_gradients,
                                                      self.discriminator_x.trainable_variables))

        self.discriminator_y_optimizer.apply_gradients(zip(disc_y_gradients,
                                                      self.discriminator_y.trainable_variables))

    @tf.function
    def train_step(self, real_x, real_y):
        gen_g_gradients, gen_f_gradients, disc_x_gradients, disc_y_gradients = self.compute_gradients( real_x, real_y)
        self.apply_gradients(gen_g_gradients, gen_f_gradients, disc_x_gradients, disc_y_gradients)

    def restore_from_ckpt(self, checkpoint_dir):

        # restoring the latest checkpoint in checkpoint_dir
        self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_dir))

    def fit(self, trainX_ds, trainY_ds,
            testX_ds, testY_ds,
            epoches, num_batches,
            image_save_dir, checkpoint_prefix, save_internal=10):
        """

        :param train_ds:
        :param epoches:
        :param num_batches:
        :param image_save_dir:
        :param checkpoint_prefix:
        :param save_internal:
        :return:
        """
        sample_X = next(iter(trainX_ds))
        sample_Y = next(iter(trainY_ds))
        ckpt_manager = tf.train.CheckpointManager(self.ckpt, checkpoint_prefix, max_to_keep=5)
        for epoch in range(epoches):
            start = time.time()
            for batch_index, [image_x, image_y] in tqdm(
                    zip(range(num_batches),  tf.data.Dataset.zip((trainX_ds, trainY_ds))), total=num_batches):
                self.train_step(image_x, image_y)
            # æµ‹è¯•ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•ˆæžœï¼Œ ä»Žè®­ç»ƒé›†ä¸­é‡‡æ ·
            saving_path = '{}/image_at_epoch_{:04d}.png'.format(image_save_dir, epoch)
            generate_images(self.generator_g, sample_X, saving_path)

            if not epoch % save_internal:
                ckpt_save_path = ckpt_manager.save()

                print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,
                                                                    ckpt_save_path))
            print('Time taken for epoch {} is {} sec\n'.format(epoch + 1,
                                                               time.time() - start))


if __name__ == '__main__':
    # è¯»å–é…ç½®ä¸­çš„å‚æ•°
    Params = read_json(args.config_path)
    print(Params["description"])
    # è®­ç»ƒå‚æ•°è®¾ç½®
    batch_size = Params["train_config"]["batch_size"]
    sample_image_dir = Params["log_dir"] + "/sample_images"
    gen_x_dir = Params["log_dir"] + "/gen_x_domain"
    gen_y_dir = Params["log_dir"] + "/gen_y_domain"
    checkpoint_dir = Params["log_dir"] + './training_checkpoints'
    resize_shape = Params["train_config"]["resize_shape"]
    crop_shape = Params["train_config"]["crop_shape"]
    buffer_size = Params["train_config"]["buffer_size"]
    n_epochs = Params["train_config"]["n_epoches"]
    LAMBDA = Params["train_config"]["lambda"]
    OUTPUT_CHANNELS = Params["train_config"]["ouput_channels"]
    # æ•°æ®æ¥æº
    train_X_dir = Params["data"]["train_X_dir"]
    test_X_dir = Params["data"]["test_X_dir"]
    train_Y_dir = Params["data"]["train_Y_dir"]
    test_Y_dir = Params["data"]["test_Y_dir"]

    # åˆ›å»ºæ–‡ä»¶å¤¹
    for folder in [sample_image_dir, checkpoint_dir, gen_x_dir, gen_y_dir]:
        check_make_folders(folder)

    # è®¡ç®—num_batches + å¯¼å…¥dataset
    num_train_examples = len(glob(os.path.join(train_X_dir, "*")))
    num_batches = math.ceil(num_train_examples / batch_size)

    # ç»„ç»‡æ•°æ®
    train_X_ds = make_dataset(train_X_dir,
                              batch_size=batch_size,
                              resize_shape=resize_shape,
                              crop_shape=crop_shape,
                              is_training=True,
                              buffer_size=buffer_size)

    train_Y_ds = make_dataset(train_Y_dir,
                              batch_size=batch_size,
                              resize_shape=resize_shape,
                              crop_shape=crop_shape,
                              is_training=True,
                              buffer_size=buffer_size,
                              channels=OUTPUT_CHANNELS)

    test_X_ds = make_dataset(test_X_dir,
                             batch_size=batch_size,
                             resize_shape=resize_shape,
                             crop_shape=crop_shape,
                             is_training=False,
                             buffer_size=buffer_size,
                             channels=OUTPUT_CHANNELS)

    test_Y_ds = make_dataset(test_Y_dir,
                              batch_size=batch_size,
                              resize_shape=resize_shape,
                              crop_shape=crop_shape,
                              is_training=False,
                              buffer_size=buffer_size)

    # å¯¼å…¥pixel2pixel çš„æ¨¡åž‹
    generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')
    generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')

    discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)
    discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)

    # å®šä¹‰ä¼˜åŒ–å™¨
    generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

    discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

    cycle_gan_model = Cycle_gan(generator_g=generator_g,
                                generator_f=generator_f,
                                discriminator_x=discriminator_x,
                                discriminator_y=discriminator_y,
                                generator_g_optimizer=generator_g_optimizer,
                                generator_f_optimizer=generator_f_optimizer,
                                discriminator_x_optimizer=discriminator_x_optimizer,
                                discriminator_y_optimizer=discriminator_y_optimizer,
                                LAMBDA=LAMBDA
                                )
    # TODO è®­ç»ƒ
    # cycle_gan_model.fit(trainX_ds=train_X_ds, trainY_ds=train_Y_ds, testX_ds=test_X_ds, testY_ds=test_Y_ds,
    #                     epoches=n_epochs, num_batches=num_batches,
    #                     image_save_dir=sample_image_dir, checkpoint_prefix=checkpoint_dir, save_internal=10)

    # TODO restore,restore ä¸Žload modelçš„åŒºåˆ«åœ¨äºŽå®ƒä¼šæ¢å¤æ‰€æœ‰çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬è®­ç»ƒçŠ¶æ€
    cycle_gan_model.restore_from_ckpt(checkpoint_dir)
    # æµ‹è¯• ç”Ÿæˆå›¾ç‰‡X->Y
    test_dataset(cycle_gan_model.generator_g, test_X_ds, gen_x_dir)
    # æµ‹è¯•å›¾ç‰‡ Y-X
    test_dataset(cycle_gan_model.generator_f, test_Y_ds, gen_y_dir)



